{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVDUN0gxCaiL",
        "outputId": "450e9551-da8b-4b06-916e-1f7cab20a579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "#!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk_OIYdz-0H1"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U6iw6Z0MDA1K"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8v5rnmusK3r"
      },
      "source": [
        "Start a new Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "00owVLQCDHCI"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erAOUMxPwtlr"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEg5XwL2pI8q"
      },
      "source": [
        "The data is stored in daily files. Let's read those in and concatenate them in a single data frame\n",
        "- Firstly, set the parent path where all subfolders containing files are stored.\n",
        "- Then loop through each subfolder inside the parent directory\n",
        "- Check if the is the valid directory\n",
        "- Read each `.parquet` file into a Spark Dataframe\n",
        "- Add a new column \"Month\" extracted from the `datetime` column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWv_Lg8FpHoL"
      },
      "outputs": [],
      "source": [
        "parent_path = \"/content/drive/MyDrive/Colab Notebooks/data\"\n",
        "folder_names = sorted(os.listdir(parent_path))\n",
        "all_dfs = []\n",
        "\n",
        "for folder in folder_names:\n",
        "    full_path = os.path.join(parent_path, folder)\n",
        "    if os.path.isdir(full_path):\n",
        "        parquet_files = [f for f in os.listdir(full_path) if f.endswith(\".parquet\")]\n",
        "\n",
        "        for parquet_file in parquet_files:\n",
        "            file_path = os.path.join(full_path, parquet_file)\n",
        "            df_temp = spark.read.parquet(file_path)\n",
        "            df_temp = df_temp.withColumn(\"Month\", date_format(col(\"datetime\"), \"MM\"))\n",
        "            all_dfs.append(df_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew900WE2qtT_"
      },
      "source": [
        "Merge all DataFrames from different days/months into a single DataFrame using `unionByName`. We will need to investigate both `user_id` and `keyword` columns so we need to make sure that there is not any missing value. We'll also need to include only the rows where `action` is `search`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5UrthCyjDRxi"
      },
      "outputs": [],
      "source": [
        "df = all_dfs[0]\n",
        "for df_next in all_dfs[1:]:\n",
        "    df = df.unionByName(df_next)\n",
        "    df = df.filter((col('action') == 'search') & (col('user_id').isNotNull()) & (col('keyword').isNotNull()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JK9hjHfw2yj"
      },
      "source": [
        "## Inspecting and Transforming Log Search Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40X3ldkhr5qg"
      },
      "source": [
        "Let's visually inspect the beginning of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUqi_WAIBlGW",
        "outputId": "de1b7c34-f08d-4530-e5ec-3a09d895847b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------+--------------------+--------+---------+--------------------+-----------+------+--------------------+-----+\n",
            "|             eventID|            datetime| user_id|             keyword|category|proxy_isp|            platform|networkType|action|        userPlansMap|Month|\n",
            "+--------------------+--------------------+--------+--------------------+--------+---------+--------------------+-----------+------+--------------------+-----+\n",
            "|22c35287-9fe1-487...|2022-06-01 18:59:...|44887906|            trữ tình|   enter|     vnpt|   fplay-ottbox-2019|   ethernet|search|                  []|   06|\n",
            "|f9af5a95-1f72-486...|2022-06-01 18:59:...| 2719170|              bolero|   enter|  viettel|   fplay-ottbox-2019|   ethernet|search|[Kênh Gia Đình:pr...|   06|\n",
            "|d51e6e6c-2765-4a8...|2022-06-01 19:00:...| 8830996|cậu mang à sĩ hanako|   enter|     vnpt|smarttv-sony-android|       wifi|search|[Kênh Gia Đình:pr...|   06|\n",
            "|3948ea18-8c86-451...|2022-06-01 19:00:...|41559909|liên minh công lý...|   enter|     vnpt|     smart-tv-normal|       wifi|search|[Kênh Gia Đình:gi...|   06|\n",
            "|89c4f55f-d8e0-4b6...|2022-06-01 19:00:...|49026196|    việt nam vs appa|    quit|     vnpt|             android|       wifi|search|                  []|   06|\n",
            "|261329ee-9b91-47d...|2022-06-01 19:00:...|41376437|nhất kiến khuynh tâm|   enter|  viettel|smart-tv-normal-n...|       wifi|search|                  []|   06|\n",
            "|9a31a703-ac4f-45e...|2022-06-01 19:00:...| 1254139|                giác|   enter|  viettel|         web-playfpt|       NULL|search|                  []|   06|\n",
            "|bb7ac7cf-abc6-473...|2022-06-01 19:00:...|42534799|            nexsport|   enter|     vnpt|                 ios|       WIFI|search|[Kênh Quốc Tế:pro...|   06|\n",
            "|9b94a851-a1db-446...|2022-06-01 19:00:...|49190631|Tìm kiếm bằng giọ...|   enter|     vnpt|smarttv-sony-android|   ethernet|search|                  []|   06|\n",
            "|68bcd92c-6156-421...|2022-06-01 19:00:...|91485275|một mảnh băng tâm...|    quit|     vnpt|             android|       wifi|search|                  []|   06|\n",
            "+--------------------+--------------------+--------+--------------------+--------+---------+--------------------+-----------+------+--------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YD7CcUPr-OB"
      },
      "source": [
        "We need to identify the most frequently searched keyword for each `user_id` during a specified month\n",
        "- Filters the DataFrame to include only rows from the specified month\n",
        "- Groups the data by `user_id`, `keyword`, and `Month` to count how many times each keyword was searched by each user during that month\n",
        "- Defines a window function that partitions the data by `user_id` and orders rows within each user by `Total_search` in descending order\n",
        "- Assigns a rank to each keyword per user based on the number of times it was searched and filters to keep only the top-ranked keyword per user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h0KDtpefGCD4"
      },
      "outputs": [],
      "source": [
        "def most_search(df, month):\n",
        "    df = df.filter(col('Month') == month)\n",
        "    df = df.select('user_id', 'keyword', 'Month')\n",
        "    df = df.groupBy('user_id', 'keyword', 'Month').count()\n",
        "    df = df.withColumnRenamed('count', 'Total_search').orderBy('Total_search', ascending= False)\n",
        "    window = Window.partitionBy('user_id').orderBy(col('Total_search').desc())\n",
        "    df = df.withColumn('Rank', row_number().over(window))\n",
        "    df = df.filter(col('Rank') == 1)\n",
        "    df = df.withColumnRenamed('keyword','Most_Search')\n",
        "    df = df.select('user_id','Most_Search', 'Month')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zmWmZIKKwJeT"
      },
      "outputs": [],
      "source": [
        "df_t6 = most_search(df, month = 6)\n",
        "df_t7 = most_search(df, month = 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYwwIwxhtZXO"
      },
      "source": [
        "- Read the file that maps each keyword to a category\n",
        "- Convert the Pandas DataFrame to a Spark DataFrame (`key_category`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9w8851dw01V"
      },
      "outputs": [],
      "source": [
        "key_category_pd = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/mapping-keywords-with-category.xlsx')\n",
        "key_category = spark.createDataFrame(key_category_pd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMY3fRuiu1sy"
      },
      "source": [
        "- Join June (T6) and July (T7) search results with category info\n",
        "- Inner join the two DataFrames on `user_id` to align T6 and T7 search data for the same user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l80aTVsPw38-"
      },
      "outputs": [],
      "source": [
        "df_t6 = df_t6.join(key_category, 'Most_Search', 'inner').select('user_id', 'Most_Search', 'Category')\n",
        "df_t6 = df_t6.withColumnRenamed('Most_Search', 'Most_Search_T6')\\\n",
        "              .withColumnRenamed('Category', 'Category_T6')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Pv8zozNWw5A0"
      },
      "outputs": [],
      "source": [
        "df_t7 = df_t7.join(key_category, 'Most_Search', 'inner').select('user_id', 'Most_Search', 'Category')\n",
        "df_t7 = df_t7.withColumnRenamed('Most_Search', 'Most_Search_T7')\\\n",
        "              .withColumnRenamed('Category', 'Category_T7')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eQ_6pda7w64X"
      },
      "outputs": [],
      "source": [
        "merge_df = df_t6.join(df_t7, 'user_id', 'inner')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYNixz7uv34W"
      },
      "source": [
        "Detecting category changes - this is useful for user behavior analysis:\n",
        "- Tracking how users shift their interests over time by comparing the user's top category from June and July"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q64QC_h7w-Vp",
        "outputId": "dbde6ce8-65a2-4f96-eef1-b71e9e22dbbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|user_id|      Most_Search_T6|         Category_T6|      Most_Search_T7|         Category_T7|     Category_Change|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|0014111|         running man|        Reality Show|        cẩm y chi hạ|Historical / Costume|Reality Show - Hi...|\n",
            "|0015590|tấm cám: chuyện c...|Historical / Costume|    taxi, em tên gì?|              Comedy|Historical / Cost...|\n",
            "|0019920|           thiếu nhi|     Anime / Cartoon|              bolero|               Music|Anime / Cartoon -...|\n",
            "|0026325|               mẹ ma|Horror / Supernat...|               mẹ ma|Horror / Supernat...|           No Change|\n",
            "|0036165|            trữ tình|               Music|            trữ tình|               Music|           No Change|\n",
            "|0048616|         penthouse 2|               Drama|      shooting stars|             Romance|     Drama - Romance|\n",
            "|0066474|    yêu nhầm chị dâu|             Romance|danh sách mua sắm...|    Crime / Thriller|Romance - Crime /...|\n",
            "|0085143|hoa nở trăng vừa ...|             Romance|   diên hy công lược|Historical / Costume|Romance - Histori...|\n",
            "|0085729|cô nàng trong trắ...|             Romance|  thiên nga bóng đêm|               Drama|     Romance - Drama|\n",
            "|0092766|           siêu nhân|             Fantasy|           siêu nhân|             Fantasy|           No Change|\n",
            "|0097626|         hoa của quỷ|    Crime / Thriller|             tư đằng|             Fantasy|Crime / Thriller ...|\n",
            "|0114796|       one punch man|     Anime / Cartoon|           dr. stone|     Anime / Cartoon|           No Change|\n",
            "|0153643|yêu em từ cái nhì...|             Romance|10 năm 3 tháng 30...|             Romance|           No Change|\n",
            "|0159890|          fairy tail|     Anime / Cartoon|              TOTORO|     Anime / Cartoon|           No Change|\n",
            "|0166772|          khủng long|Mystery / Psychol...|           siêu nhân|             Fantasy|Mystery / Psychol...|\n",
            "|0173055|       vườn sao băng|             Romance|         penthouse 2|               Drama|     Romance - Drama|\n",
            "|0177631|            trữ tình|               Music|            trữ tình|               Music|           No Change|\n",
            "|0180081|            trữ tình|               Music|            trữ tình|               Music|           No Change|\n",
            "|0183437|      vượt ra tội ác|    Crime / Thriller|công tố viên quân...|    Crime / Thriller|           No Change|\n",
            "|0183627|         ngự giao ký|             Fantasy|   thanh xuân vật vã|             Romance|   Fantasy - Romance|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "condition = (col('Category_T6') == col('Category_T7'))\n",
        "merge_df = merge_df.withColumn('Category_Change', when(condition, 'No Change').otherwise(concat(merge_df['Category_T6'], lit(' - '), merge_df['Category_T7'])))\n",
        "merge_df.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
